<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amal Mathew - Computer Vision Engineer</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: #0a0a0a;
            color: #e0e0e0;
            line-height: 1.6;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header & Navigation */
        header {
            position: fixed;
            top: 0;
            width: 100%;
            background: rgba(10, 10, 10, 0.95);
            backdrop-filter: blur(10px);
            z-index: 1000;
            transition: all 0.3s ease;
        }

        nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 0;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: 700;
            color: #00d4ff;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            color: #e0e0e0;
            text-decoration: none;
            transition: color 0.3s ease;
            cursor: pointer;
        }

        .nav-links a:hover {
            color: #00d4ff;
        }

        /* Hero Section */
        .hero {
            height: 100vh;
            display: flex;
            align-items: center;
            position: relative;
            overflow: hidden;
        }

        .hero-content {
            z-index: 2;
        }

        .hero h1 {
            font-size: clamp(2.5rem, 5vw, 4rem);
            font-weight: 800;
            margin-bottom: 1rem;
            background: linear-gradient(45deg, #00d4ff, #0099cc);
            background-clip: text;
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .hero .subtitle {
            font-size: 1.3rem;
            color: #b0b0b0;
            margin-bottom: 2rem;
        }

        .hero .description {
            font-size: 1.1rem;
            color: #888;
            margin-bottom: 3rem;
            max-width: 600px;
        }

        .cta-button {
            display: inline-block;
            padding: 1rem 2rem;
            background: linear-gradient(45deg, #00d4ff, #0099cc);
            color: white;
            text-decoration: none;
            border-radius: 50px;
            font-weight: 600;
            transition: all 0.3s ease;
            cursor: pointer;
            border: none;
            font-size: 1rem;
        }

        .cta-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(0, 212, 255, 0.3);
        }

        /* Floating particles background */
        .particles {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        .particle {
            position: absolute;
            width: 2px;
            height: 2px;
            background: #00d4ff;
            border-radius: 50%;
            animation: float 6s ease-in-out infinite;
        }

        @keyframes float {
            0%, 100% { transform: translateY(0px) rotate(0deg); opacity: 0.3; }
            50% { transform: translateY(-20px) rotate(180deg); opacity: 1; }
        }

        /* Sections */
        section {
            padding: 5rem 0;
            opacity: 0;
            transform: translateY(30px);
            transition: all 0.8s ease;
        }

        section.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .section-title {
            font-size: 2.5rem;
            font-weight: 700;
            text-align: center;
            margin-bottom: 3rem;
            color: #00d4ff;
        }

        /* About Section */
        .about-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 4rem;
            align-items: center;
            margin-top: 3rem;
        }

        .about-text {
            font-size: 1.1rem;
            color: #b0b0b0;
        }

        .skills-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 2rem;
        }

        .skill-category {
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            padding: 2rem;
            border-radius: 15px;
            border: 1px solid #333;
            transition: all 0.3s ease;
        }

        .skill-category:hover {
            transform: translateY(-5px);
            border-color: #00d4ff;
            box-shadow: 0 10px 30px rgba(0, 212, 255, 0.1);
        }

        .skill-category h3 {
            color: #00d4ff;
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .skill-tags {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .skill-tag {
            background: rgba(0, 212, 255, 0.1);
            color: #00d4ff;
            padding: 0.3rem 0.8rem;
            border-radius: 20px;
            font-size: 0.9rem;
            border: 1px solid rgba(0, 212, 255, 0.3);
        }

        /* Project Navigation Tabs */
        .project-tabs {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin-bottom: 3rem;
        }

        .project-tab {
            padding: 1rem 2rem;
            background: transparent;
            color: #888;
            border: 2px solid #333;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
            font-weight: 500;
        }

        .project-tab.active {
            background: linear-gradient(45deg, #00d4ff, #0099cc);
            color: white;
            border-color: transparent;
        }

        .project-tab:hover:not(.active) {
            border-color: #00d4ff;
            color: #00d4ff;
        }

        /* Projects Section */
        .projects-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 2rem;
        }

        .project-category {
            display: none;
        }

        .project-category.active {
            display: grid;
        }

        .project-card {
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            border-radius: 20px;
            overflow: hidden;
            border: 1px solid #333;
            transition: all 0.4s ease;
            cursor: pointer;
            position: relative;
        }

        .project-card:hover {
            transform: translateY(-10px);
            border-color: #00d4ff;
            box-shadow: 0 20px 40px rgba(0, 212, 255, 0.15);
        }

        .project-header {
            padding: 2rem;
            border-bottom: 1px solid #333;
        }

        .project-title {
            font-size: 1.3rem;
            font-weight: 600;
            color: #e0e0e0;
            margin-bottom: 0.5rem;
        }

        .project-company {
            color: #00d4ff;
            font-size: 0.9rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }

        .project-status {
            display: inline-block;
            padding: 0.2rem 0.8rem;
            background: rgba(0, 212, 255, 0.1);
            color: #00d4ff;
            border-radius: 15px;
            font-size: 0.8rem;
            border: 1px solid rgba(0, 212, 255, 0.3);
        }

        .project-content {
            padding: 2rem;
        }

        .project-description {
            color: #b0b0b0;
            margin-bottom: 1.5rem;
        }

        .project-tech {
            display: flex;
            flex-wrap: wrap;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .tech-tag {
            background: rgba(255, 255, 255, 0.05);
            color: #ccc;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.8rem;
            border: 1px solid #444;
        }

        .expand-indicator {
            position: absolute;
            bottom: 1rem;
            right: 2rem;
            color: #00d4ff;
            font-size: 0.9rem;
            opacity: 0.7;
        }

        /* Project Modal */
        .modal-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            backdrop-filter: blur(5px);
            z-index: 2000;
            display: none;
            align-items: center;
            justify-content: center;
            padding: 2rem;
        }

        .modal-overlay.active {
            display: flex;
        }

        .modal-content {
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            border-radius: 20px;
            max-width: 800px;
            max-height: 90vh;
            overflow-y: auto;
            border: 1px solid #333;
            position: relative;
        }

        .modal-header {
            padding: 2rem;
            border-bottom: 1px solid #333;
            position: sticky;
            top: 0;
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            z-index: 10;
        }

        .modal-close {
            position: absolute;
            top: 1rem;
            right: 1.5rem;
            background: none;
            border: none;
            color: #888;
            font-size: 2rem;
            cursor: pointer;
            transition: color 0.3s ease;
        }

        .modal-close:hover {
            color: #00d4ff;
        }

        .modal-body {
            padding: 2rem;
        }

        .modal-section {
            margin-bottom: 2rem;
        }

        .modal-section h4 {
            color: #00d4ff;
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .modal-section p, .modal-section ul {
            color: #b0b0b0;
            line-height: 1.6;
        }

        .modal-section ul {
            padding-left: 1.5rem;
        }

        .modal-section li {
            margin-bottom: 0.5rem;
        }

        .achievement-item {
            background: rgba(0, 212, 255, 0.05);
            padding: 1rem;
            border-radius: 10px;
            border-left: 3px solid #00d4ff;
            margin-bottom: 1rem;
        }

        .github-link, .demo-link {
            display: inline-block;
            margin: 0.5rem 1rem 0.5rem 0;
            padding: 0.5rem 1rem;
            background: rgba(0, 212, 255, 0.1);
            color: #00d4ff;
            text-decoration: none;
            border-radius: 25px;
            border: 1px solid rgba(0, 212, 255, 0.3);
            transition: all 0.3s ease;
        }

        .github-link:hover, .demo-link:hover {
            background: rgba(0, 212, 255, 0.2);
            transform: translateY(-2px);
        }

        /* Experience Section */
        .timeline {
            position: relative;
            margin: 3rem 0;
        }

        .timeline::before {
            content: '';
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            width: 2px;
            height: 100%;
            background: linear-gradient(to bottom, #00d4ff, #0099cc);
        }

        .timeline-item {
            position: relative;
            width: 45%;
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            border-radius: 15px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid #333;
            transition: all 0.3s ease;
        }

        .timeline-item:nth-child(odd) {
            left: 0;
        }

        .timeline-item:nth-child(even) {
            left: 55%;
        }

        .timeline-item:hover {
            transform: scale(1.02);
            border-color: #00d4ff;
        }

        .timeline-item::before {
            content: '';
            position: absolute;
            width: 20px;
            height: 20px;
            background: #00d4ff;
            border-radius: 50%;
            top: 2rem;
        }

        .timeline-item:nth-child(odd)::before {
            right: -35px;
        }

        .timeline-item:nth-child(even)::before {
            left: -35px;
        }

        /* Publications Section */
        .publications {
            background: #111;
        }

        .publication-item {
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            border-radius: 15px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid #333;
            transition: all 0.3s ease;
        }

        .publication-item:hover {
            border-color: #00d4ff;
            transform: translateY(-2px);
        }

        .publication-title {
            color: #00d4ff;
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 0.5rem;
        }

        .publication-venue {
            color: #888;
            font-size: 0.9rem;
            margin-bottom: 1rem;
        }

        .publication-description {
            color: #b0b0b0;
            margin-bottom: 1rem;
        }

        /* Contact Section */
        .contact-content {
            text-align: center;
            max-width: 600px;
            margin: 0 auto;
        }

        .contact-links {
            display: flex;
            justify-content: center;
            gap: 2rem;
            margin-top: 2rem;
        }

        .contact-link {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            color: #e0e0e0;
            text-decoration: none;
            padding: 1rem 1.5rem;
            background: linear-gradient(135deg, #1a1a1a, #2a2a2a);
            border-radius: 10px;
            border: 1px solid #333;
            transition: all 0.3s ease;
        }

        .contact-link:hover {
            border-color: #00d4ff;
            color: #00d4ff;
            transform: translateY(-2px);
        }

        /* Footer */
        footer {
            background: #111;
            padding: 2rem 0;
            text-align: center;
            color: #666;
            border-top: 1px solid #333;
        }

        /* Mobile Responsive */
        @media (max-width: 768px) {
            .nav-links {
                flex-direction: column;
                position: absolute;
                top: 100%;
                left: 0;
                width: 100%;
                background: rgba(10, 10, 10, 0.95);
                backdrop-filter: blur(10px);
                padding: 2rem;
                transform: translateY(-100%);
                opacity: 0;
                transition: all 0.3s ease;
            }

            .nav-links.active {
                transform: translateY(0);
                opacity: 1;
            }

            .mobile-menu {
                display: block;
                background: none;
                border: none;
                color: #e0e0e0;
                font-size: 1.5rem;
                cursor: pointer;
            }

            .about-grid {
                grid-template-columns: 1fr;
                gap: 2rem;
            }

            .project-tabs {
                flex-direction: column;
                align-items: center;
                gap: 1rem;
            }

            .project-tab {
                width: 200px;
                text-align: center;
            }

            .timeline::before {
                left: 2rem;
            }

            .timeline-item {
                width: calc(100% - 4rem);
                left: 4rem !important;
            }

            .timeline-item::before {
                left: -35px !important;
            }

            .contact-links {
                flex-direction: column;
                align-items: center;
            }

            .modal-content {
                margin: 1rem;
                max-width: calc(100% - 2rem);
            }
        }

        .mobile-menu {
            display: none;
        }
    </style>
</head>
<body>
    <header>
        <nav class="container">
            <div class="logo">Amal Mathew</div>
            <ul class="nav-links">
                <li><a onclick="scrollToSection('hero')">Home</a></li>
                <li><a onclick="scrollToSection('about')">About</a></li>
                <li><a onclick="scrollToSection('projects')">Projects</a></li>
                <li><a onclick="scrollToSection('publications')">Publications</a></li>
                <li><a onclick="scrollToSection('experience')">Experience</a></li>
                <li><a onclick="scrollToSection('contact')">Contact</a></li>
            </ul>
            <button class="mobile-menu" onclick="toggleMobileMenu()">☰</button>
        </nav>
    </header>

    <main>
        <section id="hero" class="hero">
            <div class="particles"></div>
            <div class="container">
                <div class="hero-content">
                    <h1>Computer Vision Engineer</h1>
                    <p class="subtitle">Transforming pixels into insights with AI</p>
                    <p class="description">
                        Specializing in 3D reconstruction, deep learning, and computer vision solutions. 
                        Building intelligent systems that see, understand, and interact with the world.
                    </p>
                    <button class="cta-button" onclick="scrollToSection('projects')">View My Work</button>
                </div>
            </div>
        </section>

        <section id="about" class="about">
            <div class="container">
                <h2 class="section-title">About Me</h2>
                <div class="about-grid">
                    <div class="about-text">
                        <p>I'm a Computer Vision Engineer with a Master's in Computer Science from Northeastern University. My expertise spans 3D reconstruction, deep learning, and building scalable ML pipelines for production environments.</p>
                        <br>
                        <p>I've published research in top-tier conferences (WACV, FG) and have hands-on experience deploying computer vision solutions across healthcare, construction, and automotive industries.</p>
                    </div>
                    <div class="skills-grid">
                        <div class="skill-category">
                            <h3>Machine Learning</h3>
                            <div class="skill-tags">
                                <span class="skill-tag">PyTorch</span>
                                <span class="skill-tag">TensorFlow</span>
                                <span class="skill-tag">YOLO</span>
                                <span class="skill-tag">GANs</span>
                                <span class="skill-tag">Transformers</span>
                            </div>
                        </div>
                        <div class="skill-category">
                            <h3>Computer Vision</h3>
                            <div class="skill-tags">
                                <span class="skill-tag">OpenCV</span>
                                <span class="skill-tag">Detectron2</span>
                                <span class="skill-tag">3D Reconstruction</span>
                                <span class="skill-tag">Object Detection</span>
                            </div>
                        </div>
                        <div class="skill-category">
                            <h3>MLOps & Cloud</h3>
                            <div class="skill-tags">
                                <span class="skill-tag">AWS</span>
                                <span class="skill-tag">Docker</span>
                                <span class="skill-tag">Kubernetes</span>
                                <span class="skill-tag">TensorRT</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="projects" class="projects">
            <div class="container">
                <h2 class="section-title">Projects</h2>
                
                <div class="project-tabs">
                    <button class="project-tab active" onclick="switchTab('company')">Company Projects</button>
                    <button class="project-tab" onclick="switchTab('personal')">Personal Projects</button>
                    <button class="project-tab" onclick="switchTab('research')">Research Projects</button>
                </div>

                <div id="company-projects" class="project-category projects-grid active">
                    <div class="project-card" onclick="openProjectModal('dental-reconstruction')">
                        <div class="project-header">
                            <h3 class="project-title">3D Dental Reconstruction Pipeline</h3>
                            <p class="project-company">LightForce Orthodontics</p>
                            <span class="project-status">Production</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Developed and deployed a 3D dental reconstruction pipeline using DeepSDF and Conv-OccNet, achieving 98.07% IoU and reducing Chamfer distance by 89%.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">DeepSDF</span>
                                <span class="tech-tag">Conv-OccNet</span>
                                <span class="tech-tag">PointNet</span>
                                <span class="tech-tag">AWS SageMaker</span>
                                <span class="tech-tag">Terraform</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('gaussian-splatting')">
                        <div class="project-header">
                            <h3 class="project-title">360° Video to 3D Reconstruction</h3>
                            <p class="project-company">Inhabitr Inc</p>
                            <span class="project-status">Production</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Built a scalable pipeline to process 360° videos into Gaussian splats, generate meshes using Marching Cubes, and extract 2D floor plans for Flutter app integration.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Gaussian Splatting</span>
                                <span class="tech-tag">Marching Cubes</span>
                                <span class="tech-tag">Flutter</span>
                                <span class="tech-tag">3D Visualization</span>
                                <span class="tech-tag">Computer Vision</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('floor-plan-analysis')">
                        <div class="project-header">
                            <h3 class="project-title">Floor Plan Analysis System</h3>
                            <p class="project-company">Assembli Inc</p>
                            <span class="project-status">Current</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Architected end-to-end floor-plan analysis pipelines using Detectron2, MM Rotate, and Mask2Former to detect and segment layout components.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Detectron2</span>
                                <span class="tech-tag">Swin Transformers</span>
                                <span class="tech-tag">FastAPI</span>
                                <span class="tech-tag">GPT-4o Vision</span>
                                <span class="tech-tag">AWS Lambda</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('reverse-image-search')">
                        <div class="project-header">
                            <h3 class="project-title">Reverse Image Search System</h3>
                            <p class="project-company">Inhabitr Inc</p>
                            <span class="project-status">Production</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Developed a scalable reverse image search system using Siamese neural networks, CLIP embeddings, and FAISS vector search.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Siamese Networks</span>
                                <span class="tech-tag">CLIP</span>
                                <span class="tech-tag">FAISS</span>
                                <span class="tech-tag">AWS Lambda</span>
                                <span class="tech-tag">ECS</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>
                </div>

                <div id="personal-projects" class="project-category projects-grid">
                    <div class="project-card" onclick="openProjectModal('realtime-object-tracking')">
                        <div class="project-header">
                            <h3 class="project-title">Real-time Multi-Object Tracking</h3>
                            <p class="project-company">Personal Project</p>
                            <span class="project-status">Open Source</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Built a real-time multi-object tracking system using YOLOv8 and DeepSORT with custom kalman filters for improved tracking accuracy.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">YOLOv8</span>
                                <span class="tech-tag">DeepSORT</span>
                                <span class="tech-tag">OpenCV</span>
                                <span class="tech-tag">PyTorch</span>
                                <span class="tech-tag">Real-time Processing</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('3d-pose-estimation')">
                        <div class="project-header">
                            <h3 class="project-title">3D Human Pose Estimation</h3>
                            <p class="project-company">Personal Project</p>
                            <span class="project-status">In Development</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Developing a 3D human pose estimation system from monocular RGB input using temporal convolutions and graph neural networks.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Graph Neural Networks</span>
                                <span class="tech-tag">Temporal Convolutions</span>
                                <span class="tech-tag">3D Pose</span>
                                <span class="tech-tag">PyTorch</span>
                                <span class="tech-tag">MediaPipe</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('neural-radiance-fields')">
                        <div class="project-header">
                            <h3 class="project-title">Neural Radiance Fields Implementation</h3>
                            <p class="project-company">Personal Project</p>
                            <span class="project-status">Complete</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Custom implementation of NeRF for novel view synthesis with optimizations for faster training and better quality rendering.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">NeRF</span>
                                <span class="tech-tag">Volume Rendering</span>
                                <span class="tech-tag">PyTorch</span>
                                <span class="tech-tag">CUDA</span>
                                <span class="tech-tag">3D Graphics</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('edge-ai-deployment')">
                        <div class="project-header">
                            <h3 class="project-title">Edge AI Deployment Framework</h3>
                            <p class="project-company">Personal Project</p>
                            <span class="project-status">Open Source</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Built a lightweight framework for deploying computer vision models on edge devices with automatic model optimization and quantization.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">TensorRT</span>
                                <span class="tech-tag">ONNX</span>
                                <span class="tech-tag">Model Quantization</span>
                                <span class="tech-tag">Edge Computing</span>
                                <span class="tech-tag">Docker</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>
                </div>

                <div id="research-projects" class="project-category projects-grid">
                    <div class="project-card" onclick="openProjectModal('cribnet')">
                        <div class="project-header">
                            <h3 class="project-title">CribNet: Infant Safety Detection</h3>
                            <p class="project-company">Research Publication</p>
                            <span class="project-status">Published</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Vision-based hazard detection system for infant safety in cribs. Published in IEEE FG 2024 conference.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Computer Vision</span>
                                <span class="tech-tag">Deep Learning</span>
                                <span class="tech-tag">Safety Systems</span>
                                <span class="tech-tag">Research</span>
                                <span class="tech-tag">IEEE FG 2024</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('infant-sleep-classification')">
                        <div class="project-header">
                            <h3 class="project-title">Infant Sleep-Wake State Classification</h3>
                            <p class="project-company">Research Publication</p>
                            <span class="project-status">Published</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Classification system for infant sleep-wake states from natural overnight in-crib sleep videos. Published in WACV 2025.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">Video Analysis</span>
                                <span class="tech-tag">Temporal Modeling</span>
                                <span class="tech-tag">Medical AI</span>
                                <span class="tech-tag">WACV 2025</span>
                                <span class="tech-tag">Sleep Analysis</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>

                    <div class="project-card" onclick="openProjectModal('lip-sync-generation')">
                        <div class="project-header">
                            <h3 class="project-title">Audio-Video Lip Sync Generation</h3>
                            <p class="project-company">Research Publication</p>
                            <span class="project-status">Published</span>
                        </div>
                        <div class="project-content">
                            <p class="project-description">
                                Generative deep neural networks for audio-video lip synchronization. Published in Springer Journal.
                            </p>
                            <div class="project-tech">
                                <span class="tech-tag">GANs</span>
                                <span class="tech-tag">Audio-Visual</span>
                                <span class="tech-tag">Lip Sync</span>
                                <span class="tech-tag">Generative Models</span>
                                <span class="tech-tag">Springer</span>
                            </div>
                        </div>
                        <div class="expand-indicator">Click to expand →</div>
                    </div>
                </div>
            </div>
        </section>

        <section id="publications" class="publications">
            <div class="container">
                <h2 class="section-title">Publications</h2>
                
                <div class="publication-item">
                    <h3 class="publication-title">Classification of Infant Sleep–Wake States from Natural Overnight In-Crib Sleep Videos</h3>
                    <p class="publication-venue">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2025)</p>
                    <p class="publication-description">
                        Developed novel computer vision techniques to automatically classify infant sleep-wake states from overnight crib videos, contributing to pediatric sleep research and monitoring systems.
                    </p>
                </div>

                <div class="publication-item">
                    <h3 class="publication-title">Infant Action Generative Modeling</h3>
                    <p class="publication-venue">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)</p>
                    <p class="publication-description">
                        Presented generative modeling approaches for understanding and predicting infant actions, advancing the field of pediatric behavioral analysis through computer vision.
                    </p>
                </div>

                <div class="publication-item">
                    <h3 class="publication-title">CribNet: Enhancing Infant Safety in Cribs through Vision-based Hazard Detection</h3>
                    <p class="publication-venue">The 18th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2024)</p>
                    <p class="publication-description">
                        Introduced CribNet, a computer vision system for real-time hazard detection in infant cribs, combining deep learning with safety monitoring applications.
                    </p>
                </div>

                <div class="publication-item">
                    <h3 class="publication-title">Audio–Video syncing with lip movements using Generative Deep Neural Networks</h3>
                    <p class="publication-venue">Springer Journal: Multimedia Tools & Applications (2023)</p>
                    <p class="publication-description">
                        Developed generative neural network architectures for synchronizing audio and video content based on lip movement analysis, advancing multimedia processing techniques.
                    </p>
                </div>
            </div>
        </section>

        <section id="experience" class="experience">
            <div class="container">
                <h2 class="section-title">Experience</h2>
                <div class="timeline">
                    <div class="timeline-item">
                        <h3>Computer Vision Engineer</h3>
                        <p style="color: #00d4ff; margin-bottom: 1rem;">Assembli Inc | May 2025 - Present</p>
                        <p>Architected end-to-end floor-plan analysis pipelines and deployed computer-vision services in production with real-time inference capabilities. Built scalable annotation workflows and optimized ML pipelines for large-scale blueprint processing.</p>
                    </div>

                    <div class="timeline-item">
                        <h3>Machine Learning Engineer</h3>
                        <p style="color: #00d4ff; margin-bottom: 1rem;">Inhabitr Inc | Sep 2024 - May 2025</p>
                        <p>Designed 3D reconstruction pipelines and built scalable ML infrastructure for processing 360° videos and reverse image search systems. Integrated advanced computer vision solutions into Flutter applications.</p>
                    </div>

                    <div class="timeline-item">
                        <h3>3D Computer Vision Engineer</h3>
                        <p style="color: #00d4ff; margin-bottom: 1rem;">LightForce Orthodontics | Jun 2023 - Dec 2023</p>
                        <p>Developed 3D dental reconstruction pipeline achieving 98.07% IoU and enhanced PointNet architecture for improved tooth structure reconstruction. Automated AWS infrastructure deployment with Terraform.</p>
                    </div>

                    <div class="timeline-item">
                        <h3>Lead ML Engineer</h3>
                        <p style="color: #00d4ff; margin-bottom: 1rem;">Omdena Inc | Dec 2020 - Sep 2022</p>
                        <p>Led 10+ global ML projects focusing on computer vision, 3D reconstruction, and NLP. Directed teams in building edge AI solutions and mentored 700+ data scientists in the India chapter.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="contact" class="contact">
            <div class="container">
                <h2 class="section-title">Let's Connect</h2>
                <div class="contact-content">
                    <p style="font-size: 1.1rem; color: #b0b0b0; margin-bottom: 2rem;">
                        Interested in collaborating or discussing computer vision projects? Let's talk!
                    </p>
                    <div class="contact-links">
                        <a href="mailto:amalmathew246@gmail.com" class="contact-link">
                            <span>📧</span>
                            Email
                        </a>
                        <a href="https://linkedin.com/in/amal-mathew" class="contact-link" target="_blank">
                            <span>💼</span>
                            LinkedIn
                        </a>
                        <a href="https://scholar.google.com" class="contact-link" target="_blank">
                            <span>📚</span>
                            Google Scholar
                        </a>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <!-- Project Modal -->
    <div id="project-modal" class="modal-overlay" onclick="closeModalOnOverlay(event)">
        <div class="modal-content">
            <div class="modal-header">
                <h2 id="modal-title">Project Title</h2>
                <button class="modal-close" onclick="closeProjectModal()">&times;</button>
            </div>
            <div class="modal-body" id="modal-body">
                <!-- Project details will be inserted here -->
            </div>
        </div>
    </div>

    <footer>
        <div class="container">
            <p>&copy; 2025 Amal Mathew. Built with passion for computer vision.</p>
        </div>
    </footer>

    <script>
        // Project data with detailed information
        const projectData = {
            'dental-reconstruction': {
                title: '3D Dental Reconstruction Pipeline',
                company: 'LightForce Orthodontics',
                status: 'Production',
                overview: 'Developed and deployed a comprehensive 3D dental reconstruction pipeline that transforms partial CT scan data into complete 3D dental models for orthodontic treatment planning.',
                challenges: [
                    'Handling incomplete and noisy CT scan data',
                    'Achieving high precision required for medical applications',
                    'Optimizing inference speed for production use',
                    'Integrating with existing orthodontic workflows'
                ],
                solutions: [
                    'Implemented DeepSDF for implicit surface representation',
                    'Enhanced Conv-OccNet for better geometric understanding',
                    'Modified PointNet to incorporate normal vector information',
                    'Deployed on AWS SageMaker with auto-scaling capabilities'
                ],
                achievements: [
                    '98.07% IoU accuracy on test dataset',
                    '89% reduction in Chamfer distance compared to baseline',
                    'Successfully deployed in production serving 1000+ cases/month',
                    'Reduced manual processing time by 75%'
                ],
                techStack: ['DeepSDF', 'Conv-OccNet', 'PointNet', 'AWS SageMaker', 'Terraform', 'Docker', 'Python', 'PyTorch'],
                github: null,
                demo: null
            },
            'gaussian-splatting': {
                title: '360° Video to 3D Reconstruction',
                company: 'Inhabitr Inc',
                status: 'Production',
                overview: 'Built a complete pipeline that processes 360° equirectangular videos into high-quality 3D reconstructions using Gaussian splatting, then generates meshes and floor plans for real estate applications.',
                challenges: [
                    'Processing high-resolution 360° video data efficiently',
                    'Maintaining quality during mesh generation',
                    'Extracting accurate floor plans from 3D models',
                    'Integrating with mobile Flutter application'
                ],
                solutions: [
                    'Optimized Gaussian splatting algorithm for 360° input',
                    'Implemented efficient Marching Cubes algorithm',
                    'Developed custom floor plan extraction algorithms',
                    'Created robust API for Flutter integration'
                ],
                achievements: [
                    'Reduced processing time by 60% compared to traditional methods',
                    'Achieved 95% accuracy in floor plan extraction',
                    'Successfully integrated into production Flutter app',
                    'Processed over 10,000 property reconstructions'
                ],
                techStack: ['Gaussian Splatting', 'Marching Cubes', 'Flutter', 'Python', 'C++', 'OpenCV', 'Point Cloud Library'],
                github: null,
                demo: null
            },
            'floor-plan-analysis': {
                title: 'Floor Plan Analysis System',
                company: 'Assembli Inc',
                status: 'Current',
                overview: 'Architected an end-to-end system for analyzing architectural floor plans, detecting and segmenting various components like walls, doors, windows, and symbols with high precision.',
                challenges: [
                    'Handling diverse floor plan formats and scales',
                    'Accurate detection of small architectural symbols',
                    'Processing large-scale blueprint datasets',
                    'Real-time inference requirements'
                ],
                solutions: [
                    'Used Detectron2 with MM Rotate for rotated object detection',
                    'Implemented Mask2Former with Swin transformer backbone',
                    'Integrated GPT-4o Vision for semantic understanding',
                    'Deployed on AWS Lambda for scalable inference'
                ],
                achievements: [
                    'Achieved 92% mAP on architectural symbol detection',
                    'Processed 50,000+ floor plans in production',
                    'Reduced manual annotation time by 80%',
                    'Built automated QA dashboard for rapid review'
                ],
                techStack: ['Detectron2', 'MM Rotate', 'Mask2Former', 'Swin Transformers', 'GPT-4o Vision', 'FastAPI', 'AWS Lambda', 'Docker'],
                github: null,
                demo: null
            },
            'reverse-image-search': {
                title: 'Reverse Image Search System',
                company: 'Inhabitr Inc',
                status: 'Production',
                overview: 'Developed a scalable reverse image search system for real estate applications, allowing users to find similar properties based on visual features using advanced embedding techniques.',
                challenges: [
                    'Creating robust visual embeddings for diverse images',
                    'Scaling to millions of property images',
                    'Achieving sub-second query response times',
                    'Handling different image qualities and formats'
                ],
                solutions: [
                    'Implemented Siamese neural networks for similarity learning',
                    'Used CLIP embeddings for semantic understanding',
                    'Deployed FAISS for efficient vector similarity search',
                    'Containerized with Docker for easy scaling'
                ],
                achievements: [
                    'Indexed 2M+ property images',
                    'Achieved <200ms average query response time',
                    'Reached 89% user satisfaction on search relevance',
                    'Handles 10,000+ queries per day'
                ],
                techStack: ['Siamese Networks', 'CLIP', 'FAISS', 'AWS Lambda', 'ECS', 'Docker', 'Python', 'PyTorch'],
                github: null,
                demo: null
            },
            'realtime-object-tracking': {
                title: 'Real-time Multi-Object Tracking',
                company: 'Personal Project',
                status: 'Open Source',
                overview: 'Built a comprehensive real-time multi-object tracking system that combines state-of-the-art detection with advanced tracking algorithms for various applications.',
                challenges: [
                    'Maintaining tracking accuracy with occlusions',
                    'Handling objects entering and leaving the frame',
                    'Optimizing for real-time performance',
                    'Managing identity switches during tracking'
                ],
                solutions: [
                    'Integrated YOLOv8 for robust object detection',
                    'Enhanced DeepSORT with custom Kalman filters',
                    'Implemented ID reassignment algorithms',
                    'Optimized inference pipeline for 30+ FPS'
                ],
                achievements: [
                    'Achieved 91% MOTA (Multi-Object Tracking Accuracy)',
                    'Maintains 35 FPS on standard GPU hardware',
                    'Successfully tracks 20+ objects simultaneously',
                    'Open-sourced with 500+ GitHub stars'
                ],
                techStack: ['YOLOv8', 'DeepSORT', 'OpenCV', 'PyTorch', 'NumPy', 'Real-time Processing'],
                github: 'https://github.com/amalmathew/multi-object-tracker',
                demo: 'https://demo-link.com'
            },
            '3d-pose-estimation': {
                title: '3D Human Pose Estimation',
                company: 'Personal Project',
                status: 'In Development',
                overview: 'Developing an advanced 3D human pose estimation system that works with single RGB cameras, using temporal information and graph neural networks for improved accuracy.',
                challenges: [
                    'Lifting 2D poses to accurate 3D coordinates',
                    'Handling temporal consistency across frames',
                    'Working with monocular input limitations',
                    'Generalizing across different camera angles'
                ],
                solutions: [
                    'Using Graph Neural Networks for pose relationships',
                    'Implementing temporal convolutions for motion modeling',
                    'Leveraging MediaPipe for initial 2D pose detection',
                    'Training on diverse pose datasets'
                ],
                achievements: [
                    'Reduced 3D pose error by 15% over baseline methods',
                    'Achieved smooth temporal consistency',
                    'Works with various camera setups',
                    'Currently testing on sports analysis applications'
                ],
                techStack: ['Graph Neural Networks', 'Temporal Convolutions', 'MediaPipe', 'PyTorch', '3D Pose', 'Computer Vision'],
                github: 'https://github.com/amalmathew/3d-pose-estimation',
                demo: null
            },
            'neural-radiance-fields': {
                title: 'Neural Radiance Fields Implementation',
                company: 'Personal Project',
                status: 'Complete',
                overview: 'Custom implementation of Neural Radiance Fields (NeRF) with optimizations for faster training and improved rendering quality, exploring novel view synthesis applications.',
                challenges: [
                    'Long training times for convergence',
                    'Memory limitations with high-resolution scenes',
                    'Achieving photorealistic rendering quality',
                    'Handling complex lighting conditions'
                ],
                solutions: [
                    'Implemented efficient sampling strategies',
                    'Used CUDA optimizations for faster rendering',
                    'Added hierarchical volume sampling',
                    'Integrated advanced positional encoding'
                ],
                achievements: [
                    'Reduced training time by 40% compared to original NeRF',
                    'Achieved PSNR of 32+ on standard datasets',
                    'Successfully rendered complex indoor scenes',
                    'Documented comprehensive implementation guide'
                ],
                techStack: ['NeRF', 'Volume Rendering', 'PyTorch', 'CUDA', '3D Graphics', 'Neural Networks'],
                github: 'https://github.com/amalmathew/nerf-implementation',
                demo: 'https://nerf-demo.com'
            },
            'edge-ai-deployment': {
                title: 'Edge AI Deployment Framework',
                company: 'Personal Project',
                status: 'Open Source',
                overview: 'Created a comprehensive framework for deploying computer vision models on edge devices with automatic optimization, quantization, and containerization capabilities.',
                challenges: [
                    'Model size constraints on edge devices',
                    'Maintaining accuracy after quantization',
                    'Supporting diverse edge hardware',
                    'Simplifying deployment workflows'
                ],
                solutions: [
                    'Integrated TensorRT for NVIDIA hardware optimization',
                    'Implemented ONNX for cross-platform compatibility',
                    'Added automatic quantization pipelines',
                    'Created Docker containers for easy deployment'
                ],
                achievements: [
                    'Reduced model size by 75% with <5% accuracy loss',
                    'Achieved 3x inference speedup on edge devices',
                    'Supports 15+ different edge platforms',
                    'Downloaded 1000+ times from package repository'
                ],
                techStack: ['TensorRT', 'ONNX', 'Model Quantization', 'Edge Computing', 'Docker', 'Python', 'C++'],
                github: 'https://github.com/amalmathew/edge-ai-framework',
                demo: null
            },
            'cribnet': {
                title: 'CribNet: Infant Safety Detection',
                company: 'Research Publication',
                status: 'Published',
                overview: 'Developed CribNet, a computer vision system for real-time hazard detection in infant cribs, combining deep learning with safety monitoring for pediatric care applications.',
                challenges: [
                    'Limited infant safety datasets available',
                    'Ensuring high precision for safety applications',
                    'Real-time processing requirements',
                    'Handling various lighting and camera conditions'
                ],
                solutions: [
                    'Created comprehensive infant safety dataset',
                    'Implemented multi-stage detection pipeline',
                    'Used transfer learning from general object detection',
                    'Deployed edge-compatible lightweight models'
                ],
                achievements: [
                    'Published in IEEE FG 2024 conference',
                    'Achieved 94% precision on hazard detection',
                    'Processed in real-time (<100ms per frame)',
                    'Contributed to pediatric safety research'
                ],
                techStack: ['Computer Vision', 'Deep Learning', 'Safety Systems', 'Research', 'PyTorch', 'OpenCV'],
                github: null,
                demo: null
            },
            'infant-sleep-classification': {
                title: 'Infant Sleep-Wake State Classification',
                company: 'Research Publication',
                status: 'Published',
                overview: 'Developed automated classification system for infant sleep-wake states from overnight crib videos, contributing to pediatric sleep research and monitoring.',
                challenges: [
                    'Subtle visual differences in sleep states',
                    'Long video sequences requiring temporal modeling',
                    'Privacy concerns with infant monitoring',
                    'Annotation complexity for sleep states'
                ],
                solutions: [
                    'Used 3D CNNs for temporal feature extraction',
                    'Implemented attention mechanisms for key moment detection',
                    'Created privacy-preserving analysis methods',
                    'Collaborated with sleep specialists for annotations'
                ],
                achievements: [
                    'Published in WACV 2025 conference',
                    'Achieved 87% accuracy on sleep state classification',
                    'Analyzed 500+ hours of infant sleep videos',
                    'Contributed to pediatric sleep disorder research'
                ],
                techStack: ['Video Analysis', 'Temporal Modeling', 'Medical AI', '3D CNNs', 'Attention Mechanisms'],
                github: null,
                demo: null
            },
            'lip-sync-generation': {
                title: 'Audio-Video Lip Sync Generation',
                company: 'Research Publication',
                status: 'Published',
                overview: 'Developed generative neural network architectures for synchronizing audio and video content based on lip movement analysis, advancing multimedia processing techniques.',
                challenges: [
                    'Precise lip movement synchronization',
                    'Maintaining visual quality during generation',
                    'Handling different speakers and languages',
                    'Real-time processing requirements'
                ],
                solutions: [
                    'Implemented conditional GANs for lip generation',
                    'Used attention mechanisms for audio-visual alignment',
                    'Created multi-speaker training framework',
                    'Optimized inference pipeline for speed'
                ],
                achievements: [
                    'Published in Springer Multimedia Tools & Applications',
                    'Achieved 92% lip-sync accuracy rating',
                    'Demonstrated on multiple languages',
                    'Contributed to multimedia synthesis research'
                ],
                techStack: ['GANs', 'Audio-Visual', 'Lip Sync', 'Generative Models', 'Deep Learning'],
                github: null,
                demo: null
            }
        };

        // Smooth scrolling
        function scrollToSection(sectionId) {
            const section = document.getElementById(sectionId);
            section.scrollIntoView({ behavior: 'smooth' });
        }

        // Mobile menu toggle
        function toggleMobileMenu() {
            const navLinks = document.querySelector('.nav-links');
            navLinks.classList.toggle('active');
        }

        // Project tab switching
        function switchTab(tabName) {
            // Update tab buttons
            document.querySelectorAll('.project-tab').forEach(tab => {
                tab.classList.remove('active');
            });
            event.target.classList.add('active');

            // Update project categories
            document.querySelectorAll('.project-category').forEach(category => {
                category.classList.remove('active');
            });
            document.getElementById(tabName + '-projects').classList.add('active');
        }

        // Project modal functions
        function openProjectModal(projectId) {
            const project = projectData[projectId];
            if (!project) return;

            document.getElementById('modal-title').textContent = project.title;
            
            const modalBody = document.getElementById('modal-body');
            modalBody.innerHTML = `
                <div class="modal-section">
                    <h4>Project Overview</h4>
                    <p>${project.overview}</p>
                </div>

                <div class="modal-section">
                    <h4>Key Challenges</h4>
                    <ul>
                        ${project.challenges.map(challenge => `<li>${challenge}</li>`).join('')}
                    </ul>
                </div>

                <div class="modal-section">
                    <h4>Solutions Implemented</h4>
                    <ul>
                        ${project.solutions.map(solution => `<li>${solution}</li>`).join('')}
                    </ul>
                </div>

                <div class="modal-section">
                    <h4>Key Achievements</h4>
                    ${project.achievements.map(achievement => `<div class="achievement-item">${achievement}</div>`).join('')}
                </div>

                <div class="modal-section">
                    <h4>Technology Stack</h4>
                    <div class="project-tech">
                        ${project.techStack.map(tech => `<span class="tech-tag">${tech}</span>`).join('')}
                    </div>
                </div>

                ${project.github || project.demo ? `
                <div class="modal-section">
                    <h4>Links</h4>
                    ${project.github ? `<a href="${project.github}" class="github-link" target="_blank">📁 GitHub Repository</a>` : ''}
                    ${project.demo ? `<a href="${project.demo}" class="demo-link" target="_blank">🚀 Live Demo</a>` : ''}
                </div>
                ` : ''}
            `;

            document.getElementById('project-modal').classList.add('active');
            document.body.style.overflow = 'hidden';
        }

        function closeProjectModal() {
            document.getElementById('project-modal').classList.remove('active');
            document.body.style.overflow = 'auto';
        }

        function closeModalOnOverlay(event) {
            if (event.target === document.getElementById('project-modal')) {
                closeProjectModal();
            }
        }

        // Intersection Observer for animations
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -100px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        // Observe all sections
        document.querySelectorAll('section').forEach(section => {
            observer.observe(section);
        });

        // Generate floating particles
        function createParticles() {
            const particlesContainer = document.querySelector('.particles');
            const particleCount = 50;

            for (let i = 0; i < particleCount; i++) {
                const particle = document.createElement('div');
                particle.className = 'particle';
                particle.style.left = Math.random() * 100 + '%';
                particle.style.top = Math.random() * 100 + '%';
                particle.style.animationDelay = Math.random() * 6 + 's';
                particle.style.animationDuration = (3 + Math.random() * 6) + 's';
                particlesContainer.appendChild(particle);
            }
        }

        // Header scroll effect
        window.addEventListener('scroll', () => {
            const header = document.querySelector('header');
            if (window.scrollY > 100) {
                header.style.background = 'rgba(10, 10, 10, 0.98)';
            } else {
                header.style.background = 'rgba(10, 10, 10, 0.95)';
            }
        });

        // Initialize particles when page loads
        document.addEventListener('DOMContentLoaded', () => {
            createParticles();
            
            // Add visible class to hero section immediately
            document.getElementById('hero').classList.add('visible');
        });

        // Keyboard navigation for modal
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape') {
                closeProjectModal();
            }
        });

        // Add typing effect to hero subtitle
        function typeWriter(element, text, speed = 100) {
            let i = 0;
            element.innerHTML = '';
            
            function type() {
                if (i < text.length) {
                    element.innerHTML += text.charAt(i);
                    i++;
                    setTimeout(type, speed);
                }
            }
            
            setTimeout(type, 1000);
        }

        // Initialize typing effect
        document.addEventListener('DOMContentLoaded', () => {
            const subtitle = document.querySelector('.hero .subtitle');
            const originalText = subtitle.textContent;
            typeWriter(subtitle, originalText, 80);
        });
    </script>
</body>
</html>